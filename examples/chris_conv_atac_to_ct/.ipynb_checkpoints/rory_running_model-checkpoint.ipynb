{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting A Simple Model Running\n",
    "\n",
    "Goals:\n",
    "1. Re-implement Chris's code, changing things so that the data loader accepts ATAC, RNA and a function to transform RNA (here, still just selecting pre-defined cell types).\n",
    "\n",
    "2. Make a stepped up model based on convolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_count = 22463\n",
    "peak_count = 116490\n",
    "label_count = 21\n",
    "test_perc = 0.05\n",
    "\n",
    "batch_size = 20\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "epochs = 10\n",
    "loss_print_freq = 100\n",
    "eval_freq = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Load_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    This takes your ATAC data (as a directory location) and RNA data and a user defined function \n",
    "    to transform the RNA in a meaningful way.\n",
    "    \n",
    "    It stores your data, performs your transformation and sets them up in an iterable way for pytorch.\n",
    "    \"\"\"\n",
    "    def __init__(self, ATAC_path, RNA_path, r_func):\n",
    "        # main peak vs cell matrix to be fed to transformer\n",
    "        self.dataset = sc.read(ATAC_path)\n",
    "        self.X = self.dataset.X.todense()\n",
    "        \n",
    "        # get ground truth\n",
    "        self.RNA = sc.read(RNA_path)    \n",
    "        self.Y = r_func(self.RNA)\n",
    "        self.r_func = r_func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset.obs.index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = np.squeeze(np.asarray(self.Y[idx]))\n",
    "        data = np.asarray(self.X[idx])\n",
    "        data = np.squeeze(data)\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    basic feed forward model to test things out...\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed1 = nn.Linear(peak_count, 20)\n",
    "        self.fc1 = nn.Linear(20, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, label_count)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.embed1(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, ATAC, RNA, r_function):\n",
    "    \"\"\"\n",
    "    wrapping chris's learning code into a function\n",
    "    \"\"\"\n",
    "    # Log GPU status\n",
    "    is_cuda = torch.cuda.is_available()\n",
    "    logging.info(\"Cuda available: \" + str(is_cuda))\n",
    "    if is_cuda:\n",
    "        current_device = torch.cuda.current_device()\n",
    "        #torch.cuda.device(current_device)\n",
    "        device_count = torch.cuda.device_count()\n",
    "        logging.info(\"Cuda device count: \" + device_count)\n",
    "        device_name = torch.cuda.get_device_name(current_device)\n",
    "        logging.info(\"Cuda device name: \" + device_name)\n",
    "\n",
    "    logging.info('Initialising')\n",
    "\n",
    "    logging.info('Setup')\n",
    "\n",
    "    # Init parameters\n",
    "    test_num = math.floor(example_count * test_perc)\n",
    "    train_num = example_count - test_num\n",
    "\n",
    "    logging.info('Train examples: ' + str(train_num))\n",
    "    logging.info('Test examples: ' + str(test_num))\n",
    "\n",
    "    # Load and split dataset\n",
    "    logging.info('Loading and splitting dataset')\n",
    "    dataset = Load_Dataset(ATAC, RNA, r_function)\n",
    "    \n",
    "    train_set, test_set = torch.utils.data.random_split(dataset, [train_num, test_num])\n",
    "\n",
    "    train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    ## DEBUG ##\n",
    "    train_features, train_labels = next(iter(train_dataloader))\n",
    "    print(f\"Feature batch shape: {train_features.size()}\")\n",
    "    print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "    # Train model\n",
    "    logging.info('Training model')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "        test_accuracy = []\n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % loss_print_freq == loss_print_freq - 1:\n",
    "                single_loss = running_loss / loss_print_freq\n",
    "                train_losses.append(single_loss)\n",
    "                logging.info('[epoch-%d, %5d] loss: %.3f' % (epoch + 1, i + 1, single_loss))\n",
    "                running_loss = 0.0\n",
    "\n",
    "            # eval\n",
    "            if i % eval_freq == eval_freq - 1:\n",
    "                model.eval()\n",
    "                test_loss = 0.0\n",
    "                accuracy = 0.0\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in test_dataloader:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        ps = torch.exp(outputs)\n",
    "                        top_p, top_class = ps.topk(1, dim=1)\n",
    "                        equals = top_class == labels.view(*top_class.shape)\n",
    "                        test_loss += loss.item()\n",
    "                        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "                test_count = len(test_dataloader)\n",
    "                single_test_loss = test_loss / test_count\n",
    "                single_test_accuracy = accuracy / test_count\n",
    "                test_losses.append(single_test_loss)\n",
    "                test_accuracy.append(single_test_accuracy)\n",
    "                model.train()\n",
    "\n",
    "                logging.info('EVAL - [epoch-%d, %5d] test_loss: %.3f test_accuracy: %.3f' % (epoch + 1, i + 1, single_test_loss, single_test_accuracy * 100))\n",
    "\n",
    "\n",
    "    logging.info('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "atac_path = '/camp/lab/briscoej/working/Rory/transcriptomics/NeurIPS_2021/nips_2021/multiome/multiome_atac_processed_training.h5ad'\n",
    "rna_path = '/camp/lab/briscoej/working/Rory/transcriptomics/NeurIPS_2021/nips_2021/multiome/multiome_gex_processed_training.h5ad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def celltype_function(RNA):\n",
    "    \"\"\"\n",
    "    this code is taken from Chris, just to demonstrate wrapping into a function\n",
    "    \"\"\"\n",
    "    sc_raw_training = sc.read(rna_path) # load data\n",
    "    # Find cell types and get index labels\n",
    "    ct_grouped = sc_raw_training.obs.groupby(\"cell_type\").size()\n",
    "    df_ct_grouped = pd.DataFrame(ct_grouped, columns=[\"count\"])\n",
    "    df_ct_grouped = df_ct_grouped.reset_index()\n",
    "    df_ct_grouped['label_id'] = df_ct_grouped.index\n",
    "\n",
    "    # Merge label ids with obs\n",
    "    sc_raw_training.obs = sc_raw_training.obs.reset_index().merge(df_ct_grouped, on='cell_type', how='inner').set_index('index')\n",
    "    return np.array(sc_raw_training.obs.label_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now to learn, we instantiate a model, then train this model on ATAC data, given RNA data and a function to transform the RNA..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model1 = Net()\n",
    "\n",
    "train(model1, atac_path, rna_path, celltype_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model\n",
    "\n",
    "It learns! But can we build a better model?\n",
    "\n",
    "The end goal is to have an attention-based, Transformer-inspired model - but for now, let's do a simple CNN.\n",
    "\n",
    "The structure:\n",
    "\n",
    "    through 1d convolutions, with increased stride and max pools, the channel width is substantially decreased from 100k to ~5000 to ~100. Meanwhile, the single channel is expanded to multiple parallel kernels, ultimately numbering around 100. The result is a 100 x 100 square with width capturing genome space and height capturing different correlative structures; this is fed through 2d convolution layers (a slightly experimental move) to try to capture higher order interactions between the correlative structures. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_count = 22463\n",
    "peak_count = 116490\n",
    "label_count = 21\n",
    "test_perc = 0.05\n",
    "\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "epochs = 10\n",
    "loss_print_freq = 1000\n",
    "eval_freq = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    \"\"\"\n",
    "    basic feed forward model to test things out...\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # could just do two 1d convs to a feed forward network, keep simple...\n",
    "        \n",
    "        self.conv1a = nn.Conv1d(1, 1, \n",
    "                                kernel_size=128, stride=64, padding=0, dilation=1, bias=True)\n",
    "        self.conv1b = nn.Conv1d(4, 2, \n",
    "                                kernel_size=128, stride=4, padding=0, dilation=1, bias=True)\n",
    "        self.pool1d = nn.MaxPool1d(kernel_size=4)\n",
    "        self.batch1a = nn.BatchNorm1d(2)\n",
    "        self.batch1b = nn.BatchNorm1d(4)\n",
    "        \n",
    "        # I would probably get rid of these:\n",
    "        self.conv2a = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=8, stride=1, padding=1, dilation=1)\n",
    "        self.conv2b = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=8, stride=1, padding=1, dilation=1)\n",
    "        self.pool2d = nn.MaxPool2d(2,2)\n",
    "        self.batch2a = nn.BatchNorm2d(1)\n",
    "        self.batch2b = nn.BatchNorm2d(1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(80, 32)\n",
    "        self.fc2 = nn.Linear(32, label_count)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0], 1, x.shape[1])\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.conv1a(x))\n",
    "        x = self.batch1a(x)\n",
    "        x = self.pool1d(x)\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.conv1b(x))\n",
    "        x = self.batch1b(x)\n",
    "        \n",
    "        x = x.reshape(x.shape[0], 1, x.shape[1], x.shape[2])\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.conv2a(x))\n",
    "        x = self.batch2a(x)\n",
    "        x = self.pool2d(x)\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.conv2b(x))\n",
    "        x = self.batch2b(x)\n",
    "        \n",
    "        x = x.reshape(x.shape[0],-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = torch.randn(batch_size, peak_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = xi.reshape(xi.shape[0], 1, xi.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = m.conv1a(xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = m.conv1b(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 64, 427])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Cuda available: False\n",
      "INFO:root:Initialising\n",
      "INFO:root:Setup\n",
      "INFO:root:Train examples: 21340\n",
      "INFO:root:Test examples: 1123\n",
      "INFO:root:Loading and splitting dataset\n",
      "Feature batch shape: torch.Size([128, 116490])\n",
      "Labels batch shape: torch.Size([128])\n",
      "INFO:root:Training model\n",
      "INFO:root:EVAL - [epoch-1,    50] test_loss: 0.236 test_accuracy: 95.369\n",
      "INFO:root:EVAL - [epoch-1,   100] test_loss: 0.238 test_accuracy: 95.283\n",
      "INFO:root:EVAL - [epoch-1,   150] test_loss: 0.242 test_accuracy: 94.588\n",
      "INFO:root:EVAL - [epoch-2,    50] test_loss: 0.232 test_accuracy: 94.823\n",
      "INFO:root:EVAL - [epoch-2,   100] test_loss: 0.229 test_accuracy: 94.950\n",
      "INFO:root:EVAL - [epoch-2,   150] test_loss: 0.230 test_accuracy: 95.048\n",
      "INFO:root:EVAL - [epoch-3,    50] test_loss: 0.223 test_accuracy: 95.471\n",
      "INFO:root:EVAL - [epoch-3,   100] test_loss: 0.230 test_accuracy: 95.109\n",
      "INFO:root:EVAL - [epoch-3,   150] test_loss: 0.227 test_accuracy: 95.236\n",
      "INFO:root:EVAL - [epoch-4,    50] test_loss: 0.231 test_accuracy: 94.415\n",
      "INFO:root:EVAL - [epoch-4,   100] test_loss: 0.229 test_accuracy: 94.874\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-301-85d0527b1254>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matac_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrna_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcelltype_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-7ac6c362b01c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, ATAC, RNA, r_function)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mtest_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/camp/lab/briscoej/working/Rory/.conda/my_envs/python_lab/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/camp/lab/briscoej/working/Rory/.conda/my_envs/python_lab/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/camp/lab/briscoej/working/Rory/.conda/my_envs/python_lab/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/camp/lab/briscoej/working/Rory/.conda/my_envs/python_lab/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/camp/lab/briscoej/working/Rory/.conda/my_envs/python_lab/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/camp/lab/briscoej/working/Rory/.conda/my_envs/python_lab/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# scalars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/camp/lab/briscoej/working/Rory/.conda/my_envs/python_lab/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model2 = ConvNet()\n",
    "\n",
    "train(model1, atac_path, rna_path, celltype_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_lab",
   "language": "python",
   "name": "python_lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
